{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from random import randrange\n",
    "    \n",
    "from torchvision.ops import nms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cell_boundaries(image, cells=7):\n",
    "    overlay = Image.new('RGBA', image.size, (0, 0, 0, 0))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    overlay_draw = ImageDraw.Draw(overlay)\n",
    "    image_width, image_height = image.size\n",
    "    \n",
    "    fill_color = (255, 255, 128, 200)\n",
    "    \n",
    "    unit = image_width / cells\n",
    "    for idx in range(1, cells):\n",
    "        vertical_line_x = unit * idx\n",
    "        overlay_draw.line([(vertical_line_x, 0), (vertical_line_x, image_height)], fill=fill_color)\n",
    "\n",
    "    unit = image_height / cells\n",
    "    for idx in range(1, cells):\n",
    "        horizontal_line_y = unit * idx\n",
    "        overlay_draw.line([(0, horizontal_line_y), (image_width, horizontal_line_y)], fill=fill_color)\n",
    "        \n",
    "    return Image.alpha_composite(image.convert(\"RGBA\"), overlay).convert(\"RGB\")\n",
    "        \n",
    "def draw_center_cell_object(image, annotator, annotation, cells=7):\n",
    "    image_width, image_height = image.size\n",
    "    \n",
    "    fill_color = (255, 0, 0, 255)\n",
    "    \n",
    "    for item in annotation:\n",
    "        (class_id, cell_idx_x, cell_idx_y, cell_pos_x, cell_pos_y, width, height) = item\n",
    "        overlay = Image.new('RGBA', image.size, (0, 0, 0, 0))\n",
    "        overlay_draw = ImageDraw.Draw(overlay)\n",
    "\n",
    "        horizontal_unit = image_width / cells\n",
    "        vertical_unit = image_height / cells\n",
    "\n",
    "        class_name = annotator.labels[class_id]\n",
    "\n",
    "        # draw center cell as red color\n",
    "        cxmin = horizontal_unit * cell_idx_x\n",
    "        cxmax = horizontal_unit * (cell_idx_x + 1)\n",
    "        cymin = vertical_unit * cell_idx_y\n",
    "        cymax = vertical_unit * (cell_idx_y + 1)\n",
    "        \n",
    "        draw = ImageDraw.Draw(image)\n",
    "        draw.line([(cxmin, cymin), (cxmax, cymin)], fill=fill_color)\n",
    "        draw.line([(cxmax, cymin), (cxmax, cymax)], fill=fill_color)\n",
    "        draw.line([(cxmax, cymax), (cxmin, cymax)], fill=fill_color)\n",
    "        draw.line([(cxmin, cymax), (cxmin, cymin)], fill=fill_color)\n",
    "        \n",
    "        cell_obj_center_x = int(cxmin + (cell_pos_x * image_width))\n",
    "        cell_obj_center_y = int(cymin + (cell_pos_y * image_height))\n",
    "        \n",
    "        oxmin, oxmax = int(cell_obj_center_x + (width * image_width / 2)), int(cell_obj_center_x - (width * image_width / 2))\n",
    "        oymin, oymax = int(cell_obj_center_y + (height * image_height / 2)), int(cell_obj_center_y - (height * image_height / 2))\n",
    "        \n",
    "        draw.ellipse([(cell_obj_center_x - 3, cell_obj_center_y - 3), (cell_obj_center_x + 3, cell_obj_center_y + 3)], fill=(255, 0, 0), width=6)\n",
    "        draw.text((cell_obj_center_x + 8, cell_obj_center_y - 6), \"CLSID: %s\" % class_name, fill=fill_color)\n",
    "        \n",
    "        random_color_r, random_color_g, random_color_b = randrange(255), randrange(255), randrange(255)\n",
    "        overlay_color = (random_color_r, random_color_g, random_color_b, 90)\n",
    "        overlay_draw.rectangle([oxmin, oymin, oxmax, oymax], fill=overlay_color)  # draw object in random color\n",
    "        \n",
    "        image = Image.alpha_composite(image.convert(\"RGBA\"), overlay).convert(\"RGB\")\n",
    "        \n",
    "    return image\n",
    "\n",
    "# TODO: redesign based on 2 predictor output\n",
    "# ignore predictor with lower bbox confidence\n",
    "\n",
    "# model output version of draw_center_cell_object\n",
    "def draw_center_cell_object_output(image, annotator, output, confidence_threshold=0.3):\n",
    "    image_width, image_height = image.size\n",
    "    \n",
    "    fill_color = (255, 0, 0, 255)\n",
    "    \n",
    "    # output -> [30, 7, 7]\n",
    "    cells = output.shape[1] # 1, 2 indicates cell count\n",
    "    bboxes = (output.shape[0] - 20) // 5\n",
    "    assert((output.shape[0] - 20) % 5 == 0) \n",
    "    \n",
    "    # Organize bboxes for NMS algorithm\n",
    "    bbox_coordinates = []\n",
    "    bbox_scores = []\n",
    "    bbox_classes = []\n",
    "    for cell_idx_y in range(cells):\n",
    "        for cell_idx_x in range(cells):\n",
    "            for bbox_idx in range(bboxes):\n",
    "                current_predictor = output[5 * (bbox_idx):5 * (bbox_idx + 1), cell_idx_y, cell_idx_x]\n",
    "                (cell_pos_x, cell_pos_y, width, height, confidence) = torch.sigmoid(torch.from_numpy(current_predictor[:5])).numpy()\n",
    "                class_id = np.argmax(output[5 * bboxes:, cell_idx_y, cell_idx_x])\n",
    "                \n",
    "                if confidence < confidence_threshold:\n",
    "                    continue\n",
    "\n",
    "                horizontal_unit = image_width / cells\n",
    "                vertical_unit = image_height / cells\n",
    "                \n",
    "                class_name = annotator.labels[class_id]\n",
    "                obj_center_x = (cell_idx_x + cell_pos_x) / cells\n",
    "                obj_center_y = (cell_idx_y + cell_pos_y) / cells\n",
    "                oxmin, oxmax = obj_center_x - (width / 2), obj_center_x + (width / 2)\n",
    "                oymin, oymax = obj_center_y - (height / 2), obj_center_y + (height / 2)\n",
    "                \n",
    "                bbox_coordinates.append([oxmin, oymin, oxmax, oymax])\n",
    "                bbox_scores.append(confidence)\n",
    "                bbox_classes.append(class_id)\n",
    "                \n",
    "#     print(\"bbox_coordinates\", bbox_coordinates)\n",
    "#     print(\"bbox_scores\", bbox_scores)\n",
    "#     print(\"bbox_classes\", bbox_classes)\n",
    "                \n",
    "    if len(bbox_coordinates) > 0:\n",
    "        print(\"[Before NMS] BBoxes:\", len(bbox_coordinates))\n",
    "\n",
    "        bbox_coordinates = torch.from_numpy(np.array(bbox_coordinates)).float()\n",
    "        bbox_scores = torch.from_numpy(np.array(bbox_scores)).float()\n",
    "        bbox_classes = torch.from_numpy(np.array(bbox_classes)).float()\n",
    "\n",
    "        coordinates_indicies = nms(boxes=bbox_coordinates, scores=bbox_scores, iou_threshold=0.2)\n",
    "        \n",
    "#         bbox_filtered_coordinates = torch.gather(bbox_coordinates, 1, coordinates_indicies)\n",
    "#         bbox_filtered_scores = torch.gather(bbox_scores, 0, coordinates_indicies)\n",
    "#         bbox_filtered_classes = torch.gather(bbox_classes, 0, coordinates_indicies)\n",
    "\n",
    "        bbox_filtered_coordinates = bbox_coordinates.index_select(0, coordinates_indicies)\n",
    "        bbox_filtered_scores = bbox_scores.index_select(0, coordinates_indicies)\n",
    "        bbox_filtered_classes = bbox_classes.index_select(0, coordinates_indicies).int()\n",
    "        \n",
    "        print(\"[After NMS] BBoxes:\", len(bbox_filtered_coordinates))\n",
    "\n",
    "        for idx in range(bbox_filtered_coordinates.shape[0]):\n",
    "            (xmin, ymin, xmax, ymax) = bbox_filtered_coordinates[idx].numpy()\n",
    "            confidence = bbox_filtered_scores[idx].numpy()\n",
    "            class_id = bbox_filtered_classes[idx].numpy()\n",
    "            \n",
    "            oxmin, oxmax = max(xmin * image_width, 0), min(xmax * image_width, image_width - 1)\n",
    "            oymin, oymax = max(ymin * image_height, 0), min(ymax * image_height, image_height - 1)\n",
    "            \n",
    "            cell_obj_center_x, cell_obj_center_y = int(oxmin + (oxmax - oxmin) / 2), int(oymin + (oymax - oymin) / 2)\n",
    "\n",
    "            class_name = annotator.labels[class_id]\n",
    "\n",
    "            overlay = Image.new('RGBA', image.size, (0, 0, 0, 0))\n",
    "            overlay_draw = ImageDraw.Draw(overlay)\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            \n",
    "            draw.ellipse([(cell_obj_center_x - 3, cell_obj_center_y - 3), (cell_obj_center_x + 3, cell_obj_center_y + 3)], fill=(255, 0, 0), width=6)\n",
    "            draw.text((cell_obj_center_x + 8, cell_obj_center_y - 6), \"CLSID: %s\" % class_name, fill=fill_color)\n",
    "\n",
    "            random_color_r, random_color_g, random_color_b = randrange(255), randrange(255), randrange(255)\n",
    "            overlay_color = (random_color_r, random_color_g, random_color_b, int(confidence * 80))\n",
    "            overlay_draw.rectangle([oxmin, oymin, oxmax, oymax], fill=overlay_color)  # draw object in random color\n",
    "\n",
    "            image = Image.alpha_composite(image.convert(\"RGBA\"), overlay).convert(\"RGB\")\n",
    "            \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code\n",
    "\n",
    "# samples = 4\n",
    "\n",
    "# for _ in range(samples):\n",
    "#     random_sample = randrange(len(annotations))\n",
    "#     filepath, annotation = annotations[random_sample]\n",
    "\n",
    "#     image = Image.open(filepath)\n",
    "#     image = draw_cell_boundaries(image, cells=7)\n",
    "#     image = draw_center_cell_object(image, annotator, annotation, cells=7)\n",
    "    \n",
    "#     plt.figure(figsize=(15, 15))\n",
    "#     plt.imshow(np.asarray(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset and training\n",
    "- Create random 5-image batch and pass it through model.\n",
    "- We will evaluate loss via result image and intermediate output console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from maintrainer.dataset import VOCYOLOAnnotator, VOCYolo\n",
    "\n",
    "annotator = VOCYOLOAnnotator(\n",
    "    annotation_root=r'C:\\Dataset\\VOCdevkit\\VOC2008\\Annotations',\n",
    "    image_root=r'C:\\Dataset\\VOCdevkit\\VOC2008\\JPEGImages'\n",
    ")\n",
    "\n",
    "annotations = annotator.parse_annotation()\n",
    "print(\"Annotation[0]:\", annotations[0][0])\n",
    "print(\"Annotation[1]:\", annotations[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms\n",
    "from torchvision.transforms import *\n",
    "\n",
    "train_dataset = VOCYolo(\n",
    "    annotator.labels,\n",
    "    annotations,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((448, 448)),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize(\n",
    "#             mean=[0.4547857, 0.4349471, 0.40525291],\n",
    "#             std=[0.12003352, 0.12323549, 0.1392444]\n",
    "#         )\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=False, batch_size=1, num_workers=0, pin_memory=True)\n",
    "\n",
    "bunch_of_batch = []\n",
    "for i, item in enumerate(train_dataloader):\n",
    "    if i >= 4:\n",
    "        break\n",
    "    bunch_of_batch.append(item)\n",
    "    \n",
    "bunch_of_batch = [(image.cuda(non_blocking=True), label.cuda(non_blocking=True)) for (image, label) in bunch_of_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(32, 8))\n",
    "fig.suptitle(\"GT Annotation based visualization\", fontsize=24)\n",
    "for i, (image, label) in enumerate(bunch_of_batch):\n",
    "    ax = fig.add_subplot(1, 4, i + 1)\n",
    "    image = torch.squeeze(image.cpu())\n",
    "    label = torch.squeeze(label.cpu())\n",
    "    \n",
    "    image = (image.numpy().transpose((1, 2, 0)) * 255).astype(np.uint8)\n",
    "    label = label.numpy()\n",
    "    \n",
    "    image = Image.fromarray(image)\n",
    "    image = draw_cell_boundaries(image)\n",
    "    image = draw_center_cell_object(image, annotator, annotations[i][1])\n",
    "    ax.imshow(np.array(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_visualization(title = None, confidence_threshold = 0.8):\n",
    "    fig = plt.figure(figsize=(40, 10))\n",
    "    fig.suptitle(\"Output based visualization\" if title is None else title, fontsize=24)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    batched_image = torch.cat([image.cuda(non_blocking=True) for image, label in bunch_of_batch], 0)\n",
    "    batched_label = torch.cat([label for image, label in bunch_of_batch], 0)\n",
    "    \n",
    "    output = model(batched_image).detach().cpu()\n",
    "    output_images = []\n",
    "    for i in range(output.shape[0]):\n",
    "        output_images.append(output[i:i+1, :, :, :])\n",
    "    \n",
    "    for i, output in enumerate(output_images):\n",
    "        ax = fig.add_subplot(1, 4, i + 1)\n",
    "\n",
    "        image = torch.squeeze(batched_image[i].cpu())\n",
    "        output = torch.squeeze(output)\n",
    "\n",
    "        image = (image.numpy().transpose((1, 2, 0)) * 255).astype(np.uint8)\n",
    "        output = output.numpy()\n",
    "\n",
    "        image = Image.fromarray(image)\n",
    "        image = draw_cell_boundaries(image)\n",
    "        image = draw_center_cell_object_output(image, annotator, output, confidence_threshold=confidence_threshold)\n",
    "        ax.imshow(np.array(image))\n",
    "    model.train()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maintrainer.loss import YoloLoss, YoloLossOld\n",
    "from model import YOLOv1, YOLOv1Pretrainer\n",
    "import random\n",
    "import os\n",
    "\n",
    "PRETRAINED_WEIGHT = r'C:\\Workspace\\study-projects\\yolov1-torch\\prepare-torch\\.pretrained\\2021-06-16-10-44-40_FullDataset-LRDecay-Continued-From-22epoch-LowerLR_LR0.000250_BS064_WORKERS16_EPOCHS200_GPU-epoch0043-train_loss1.512860-val_loss1.674705-val_acc0.616029-val_acct50.832321.zip'\n",
    "\n",
    "if not os.path.isfile(PRETRAINED_WEIGHT):\n",
    "    print(\"Pretrained weight file %s not found!\" % args.pretrained)\n",
    "    exit(-1)\n",
    "\n",
    "checkpoint = torch.load(PRETRAINED_WEIGHT)\n",
    "# c_epoch = checkpoint['epoch'] + 1\n",
    "c_model_state_dict = checkpoint['model_state_dict']\n",
    "# c_optimizer_state_dict = checkpoint['optimizer_state_dict']\n",
    "# c_loss = checkpoint['loss']\n",
    "\n",
    "pretrainer = YOLOv1Pretrainer(classes=1000)\n",
    "pretrainer.load_state_dict(c_model_state_dict)\n",
    "model = YOLOv1(pretrainer).cuda().float()\n",
    "del pretrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loss with given pseudo output!\n",
    "criterion = YoloLoss(lambda_coord=5, lambda_noobj=0.5, debug=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)\n",
    "\n",
    "# batched_image = torch.cat([image for image, label in bunch_of_batch], 0)\n",
    "# batched_label = torch.cat([label for image, label in bunch_of_batch], 0)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(1000):\n",
    "    random.shuffle(bunch_of_batch)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] *= 0.95\n",
    "        do_visualization(title=\"Epoch %d, LR=%.8f\" % (epoch, optimizer.param_groups[0]['lr']))\n",
    "            \n",
    "#     if epoch % 50 == 0:\n",
    "#         do_visualization(title=\"Epoch %d, LR=%.8f\" % (epoch, optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "    for image, label in bunch_of_batch:\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            losses.append(loss.item())\n",
    "\n",
    "#     output = model(batched_image)\n",
    "#     loss = criterion(output, batched_label)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         losses.append(loss.item())\n",
    "    print(\"Epoch %d Loss: %.6f\" % (epoch, np.average(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.from_numpy(np.array([[[[False, False, True, False, False]]]]))\n",
    "values = torch.from_numpy(np.array([[[[1.0, 0.8, 0.2, 0.6, 0.4]]]]))\n",
    "\n",
    "keep = values * mask\n",
    "print(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training within real-dataset!\n",
    "criterion = YoloLoss(lambda_coord=5, lambda_noobj=0.5, debug=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(1000):\n",
    "    # random.shuffle(bunch_of_batch)\n",
    "    \n",
    "#     if epoch == 15:\n",
    "#         do_visualization(title=\"Epoch %d\" % epoch)\n",
    "#         for g in optimizer.param_groups:\n",
    "#             g['lr'] = 0.00005\n",
    "#     elif epoch == 30:\n",
    "#         do_visualization(title=\"Epoch %d\" % epoch)\n",
    "#         for g in optimizer.param_groups:\n",
    "#             g['lr'] = 0.00002\n",
    "#     elif epoch > 30 and epoch % 15 == 0:\n",
    "#         do_visualization(title=\"Epoch %d\" % epoch)\n",
    "#         for g in optimizer.param_groups:\n",
    "#             g['lr'] *= 0.9\n",
    "\n",
    "    if epoch % 15 == 0:\n",
    "        do_visualization(title=\"Epoch %d\" % epoch)\n",
    "        \n",
    "    for image, label in bunch_of_batch:\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "    print(\"Epoch %d Loss: %.6f\" % (epoch, np.average(losses)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-pytorch",
   "language": "python",
   "name": "conda-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
