{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fcf8b3",
   "metadata": {},
   "source": [
    "# mAP Implementation with details\n",
    "- We will implement Mean Average Precision (mAP) with pretrained YOLOv3 model (which publicly available on pytorch model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129afe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "output = torch.zeros(2, 30, 7, 7)\n",
    "label = torch.zeros(2, 25, 7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9313210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "\n",
    "class MeanAvgPrecision(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, output, label):\n",
    "        classes = 20\n",
    "        bboxes = (output.shape[1] - classes) // 5\n",
    "        assert((output.shape[1] - classes) % 5 == 0)\n",
    "        \n",
    "        index_table = self.generate_cell_index_table(output)\n",
    "        \n",
    "        for c in range(20):\n",
    "            class_mask = torch.eq(torch.argmax(output[:, -classes:, :, :], 1, keepdim=True), c)\n",
    "            \n",
    "            # [2, 10, 49], [2, 10, 0], ... [B, 5 * 2, I]\n",
    "            class_bboxes = torch.masked_select(output[:, :bboxes * 5, :, :], class_mask).view(output.shape[0], 10, -1)\n",
    "            # [2, 2, 49], [2, 2, 0], ... [B, 2, I]\n",
    "            class_bbox_indicies = torch.masked_select(index_table, class_mask).view(output.shape[0], 2, -1)\n",
    "            \n",
    "            # concat two box matrix\n",
    "            ##! TODO: idx_y, idx_x OR idx_x, idx_y ?\n",
    "            # [B, 7, I], 7 -> [x, y, w, h, c, idx_y, idx_x]\n",
    "            class_bboxes = class_bboxes.view(class_bboxes.shape[0], 5, -1)\n",
    "            class_bbox_indicies = torch.repeat_interleave(class_bbox_indicies, 2, 1).view(class_bbox_indicies.shape[0], 2, -1)\n",
    "            class_bboxes_with_index = torch.cat([class_bboxes, class_bbox_indicies], dim=1)\n",
    "            \n",
    "            confidence_indicies = torch.argsort(class_bboxes_with_index[:, 4:5], dim=0, descending=True).repeat(1, 7, 1)\n",
    "            \n",
    "            # [B, 7, 98] sorted by confidence in descending order\n",
    "            sorted_class_bboxes_with_index = torch.gather(class_bboxes_with_index, 1, confidence_indicies)\n",
    "            \n",
    "            for b in range(sorted_class_bboxes_with_index.shape[2]):\n",
    "                current_bbox = class_bboxes_with_index[:, :, b]\n",
    "                \n",
    "#             print(\"Class %d entries: \" % c, class_bboxes.shape)\n",
    "#             print(\"Class %d entry indicies must be [B, 2, I] and same B, I as above: \\n\\t\" % c, class_bbox_indicies.shape)\n",
    "            \n",
    "        return 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_cell_index_table(output):\n",
    "        index_map_x = torch.arange(0, 7, device=output.device).repeat(7)\n",
    "        index_map_y = torch.repeat_interleave(torch.arange(0, 7, device=output.device), 7)\n",
    "        index_map = torch.unsqueeze(torch.stack([index_map_y, index_map_x], dim=0).view(2, 7, 7), 0)\n",
    "        return index_map\n",
    "        # index_map -> [1, 2, 7, 7]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_iou_between(xywh1: Tensor, index1: Tensor, xywh2: Tensor, index2: Tensor) -> Tensor:\n",
    "        # xywh1, xywh2 -> [B, 4, I] (I refers to items to compare)\n",
    "        # index1, index2 -> [B, 2, I] (same as above, only has y, x of their I rows)\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_iou_xywh(input_xywh: Tensor, label_xywh: Tensor) -> Tensor:\n",
    "        index_map_x = torch.arange(0, 7, device=input_xywh.device).repeat(7)\n",
    "        index_map_y = torch.repeat_interleave(torch.arange(0, 7, device=input_xywh.device), 7)\n",
    "        index_map = torch.unsqueeze(torch.stack([index_map_y, index_map_x], dim=0).view(2, 7, 7), 0)\n",
    "        input_xy_global = (input_xywh[:, :2, :, :] + index_map) / 7\n",
    "        input_width_half, input_height_half = (input_xywh[:, 2, :, :] / 2), (input_xywh[:, 3, :, :] / 2)\n",
    "        input_xmin = input_xy_global[:, 0, :, :] - input_width_half  # x_center - width / 2\n",
    "        input_xmax = input_xy_global[:, 0, :, :] + input_width_half\n",
    "        input_ymin = input_xy_global[:, 1, :, :] - input_height_half\n",
    "        input_ymax = input_xy_global[:, 1, :, :] + input_height_half\n",
    "\n",
    "        label_xy_global = (label_xywh[:, :2, :, :] + index_map) / 7\n",
    "        label_width_half, label_height_half = (label_xywh[:, 2, :, :] / 2), (label_xywh[:, 3, :, :] / 2)\n",
    "        label_xmin = label_xy_global[:, 0, :, :] - label_width_half  # x_center - width / 2\n",
    "        label_xmax = label_xy_global[:, 0, :, :] + label_width_half\n",
    "        label_ymin = label_xy_global[:, 1, :, :] - label_height_half\n",
    "        label_ymax = label_xy_global[:, 1, :, :] + label_height_half\n",
    "\n",
    "        input_volume = input_xywh[:, 2, :, :] * input_xywh[:, 3, :, :]\n",
    "        label_volume = label_xywh[:, 2, :, :] * label_xywh[:, 3, :, :]\n",
    "        intersect_width = torch.minimum(input_xmax, label_xmax) - torch.maximum(input_xmin, label_xmin)\n",
    "        intersect_height = torch.minimum(input_ymax, label_ymax) - torch.maximum(input_ymin, label_ymin)\n",
    "        intersect_volume = intersect_width * intersect_height\n",
    "        union_volume = input_volume + label_volume - intersect_volume\n",
    "\n",
    "        return intersect_volume / union_volume\n",
    "        \n",
    "mean_avg_precision = MeanAvgPrecision()\n",
    "print(mean_avg_precision(output, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb3e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.repeat_interleave(torch.Tensor([[1], [2], [3]]), 4, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
